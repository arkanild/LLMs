{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745a199-c365-4865-b5aa-14f3dfb44280",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq markdownify --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f71d504-4cc1-4018-9d1b-3f3f09d85dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq pypdf --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9defc-b815-4659-a720-9d330a074b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq transformers --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338f999-e206-45c9-9237-994ddca9c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq huggingface_hub --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ceb7a-abc6-4023-9fbe-29a471d32edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq reportlab --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9a7eb-0688-447d-ab38-62e9c90d7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199a494-9c20-47e2-974d-470f11964bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaaa5ba-2d0b-46b1-93e8-7742b3cfc2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq markdown --progress-bar-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06a71a-8b08-41fc-8a84-db7348de55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31102b-abae-4043-84d0-636f05776938",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qqq requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad37822-f7a6-4a24-bdd2-f499f53e3e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pypdf\n",
    "import requests\n",
    "import pandas as pd\n",
    "from markdownify import markdownify\n",
    "import markdown\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from huggingface_hub import InferenceClient\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0131b9-79e4-4d7a-a09a-b64f2f3340dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hugging Face API token from environment variable\n",
    "HF_TOKEN = \"<your hugging face token>\"  # Replace with your actual token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc5f5d-693f-4f0c-a4d9-271cb25b0ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_markdown(pdf_path):\n",
    "    \"\"\"Converts a PDF resume to Markdown format and stores it in a Pandas DataFrame.\"\"\"\n",
    "    text = \"\"\n",
    "    \n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        reader = pypdf.PdfReader(pdf_file)\n",
    "        for page in reader.pages:\n",
    "            extracted_text = page.extract_text()\n",
    "            if extracted_text:\n",
    "                text += extracted_text + \"\\n\\n\"\n",
    "    \n",
    "    markdown_text = markdownify(text)\n",
    "    df = pd.DataFrame({\"Markdown_Resume\": [markdown_text]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31ab6a-b437-4ab6-bafb-03922d9cdbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the model before prompting it\n",
    "# client = InferenceClient(model=\"HuggingFaceH4/zephyr-7b-beta\", token=HF_TOKEN)\n",
    "# client = InferenceClient(model=\"Qwen/QwQ-32B\", token = HF_TOKEN)\n",
    "\n",
    "# test_response = client.text_generation(\"You are a resume optimiser\", max_new_tokens=50)\n",
    "# print(test_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c4e01-d999-4fd3-8143-7fb58adf75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_resume(markdown_resume, job_description, hf_token):\n",
    "    \"\"\"Uses Hugging Face Inference API to optimize the resume while keeping its format intact.\"\"\"\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "    headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "    \n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    You are an AI assistant specialized in providing helpful, detailed, and polite answers. \n",
    "    Your task is to **rewrite resumes** to align with job descriptions while strictly maintaining the original format.\n",
    "    - Identify important keywords and skills from the job description and integrate them naturally into the resume.\n",
    "    - Modify experience and skills sections to highlight achievements relevant to the job description.\n",
    "    - Remove or downplay less relevant details while keeping the resume structure intact.\n",
    "    - Ensure strong action-oriented language and quantified achievements where possible.\n",
    "    - Preserve proper Markdown formatting in the updated resume.\n",
    "    \"\"\".strip()\n",
    "\n",
    "    prompt = f\"\"\"[INST] <<SYS>>\n",
    "    {SYSTEM_PROMPT}\n",
    "    <</SYS>>\n",
    "\n",
    "    Here is a resume:\n",
    "    {markdown_resume}\n",
    "\n",
    "    And here is the job description:\n",
    "    {job_description}\n",
    "\n",
    "    Please optimize the resume to match the job description while keeping its original format.\n",
    "    [/INST]\"\"\"\n",
    "\n",
    "    \n",
    "    payload = {\"inputs\": prompt, \"parameters\": {\"max_new_tokens\": 2048, \"temperature\": 0.7, \"do_sample\": True}}\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        output = response.json()\n",
    "        print(\"\\n=== AI Response ===\\n\", output[0][\"generated_text\"])  # Debugging step\n",
    "        return output[0][\"generated_text\"].strip()\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8342c80-499e-4f46-a4b0-2fc04bb606bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "pdf_path = \"actual_resume.pdf\"  # Replace with your PDF file path\n",
    "df = pdf_to_markdown(pdf_path)\n",
    "job_desc = \"\"\"About the Role\n",
    "As a Lead Data Engineer, you will serve as the technical anchor for the engineering team, responsible for designing and developing scalable, high-performance data solutions. You will own and drive data architecture that supports both functional and non-functional business needs, ensuring reliability, efficiency, and scalability.\n",
    "Your expertise in big data technologies, distributed systems, and cloud platforms will help shape the engineering roadmap and best practices for data processing, analytics, and real-time data serving. You will play a key role in architecting and optimizing data pipelines using Hadoop, Spark, Scala/Java, and cloud technologies to support enterprise-wide data initiatives.\n",
    "Additionally, experience with API development for serving low-latency data and Customer Data Platforms (CDP) will be a strong plus.\n",
    "\"\"\"\n",
    "new_resume = rewrite_resume(df[\"Markdown_Resume\"].iloc[0], job_desc, HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8665d35-8903-437d-80d7-0dcd95ee2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_resume_to_word(resume_text, output_path=\"optimized_resume.docx\"):\n",
    "    \"\"\"Saves the optimized resume text into a Word document.\"\"\"\n",
    "    doc = Document()\n",
    "    \n",
    "    for line in resume_text.split(\"\\n\"):\n",
    "        if line.strip():  # Avoid empty lines\n",
    "            doc.add_paragraph(line)\n",
    "    \n",
    "    doc.save(output_path)\n",
    "    print(f\"Resume saved as {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"resume.pdf\"  # Replace with your actual PDF file path\n",
    "df = pdf_to_markdown(pdf_path)\n",
    "job_desc = \"Software Engineer with Python and AI experience.\"\n",
    "new_resume = rewrite_resume(df[\"Markdown_Resume\"].iloc[0], job_desc, HF_TOKEN)\n",
    "\n",
    "# Save the AI-optimized resume to a Word document\n",
    "save_resume_to_word(new_resume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
